{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 4 - regrese (do 2. ledna)\n",
    "\n",
    "  * Cílem tohoto úkolu je vyzkoušet si řešit regresní problém na reálných (ale celkem vyčištěných) datech.\n",
    "  \n",
    "> **Nejdůležitější na úkolu je to, abyste udělali vše procesně správně: korektní rozdělení datasetu, ladění hyperparametrů, vyhodnocení výsledků atp.**\n",
    "\n",
    "## Dataset\n",
    "\n",
    "  * Zdrojem dat je list *Data* v souboru `Residential-Building-Data-Set.xlsx` na course pages (originál zde: https://archive.ics.uci.edu/ml/datasets/Residential+Building+Data+Set#).\n",
    "  * Popis datasetu najdete na listu *Descriptions* ve stejném souboru.\n",
    "  \n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "  1. Rozdělte data na trénovací a testovací množinu.\n",
    "  1. Proveďte základní průzkum dat a příp. vyhoďte nezajímavé příznaky.\n",
    "  1. Aplikujte lineární a hřebenovou regresi a výsledky řádně vyhodnoťte:\n",
    "    * K měření chyby použijte `mean_absolute_error`.\n",
    "    * Experimentujte s tvorbou nových příznaků (na základě těch dostupných).\n",
    "    * Experimentujte se standardizací/normalizací dat.\n",
    "    * Vyberte si hyperparametry modelů k ladění a najděte jejich nejlepší hodnoty.\n",
    "  1. Použijte i jiný model než jen lineární a hřebenovou regresi.\n",
    "\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-VZD/homeworks/index.html.\n",
    "  * Odevzdejte pouze tento Jupyter Notebook, opravujíví by neměl nic jiného potřebovat.\n",
    "  * Opravující Vám může umožnit úkol dodělat či opravit a získat tak další body. První verze je ale důležitá a bude-li odbytá, budete za to penalizováni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odtud už je to Vaše\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kazdou predikovanou hodnotu budeme predikovat v jednom modelu, tedy budou 2 modely, jeden pro predikci ceny prodeje, ktere nejlepe vystihuje prvnich 8 priznaku, druhy model pro stavebni cenu stavby z nejaktualnejsich dat, tedy z posledniho setu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Residential-Building-Data-Set.xlsx',list='Data',skiprows=1)\n",
    "\n",
    "SalePrice_Y=data[['V-9']]       #   predikovana hodnota pro prvni model\n",
    "CostPrice_Y=data[['V-10']]     #   predikovana hodnota pro druhy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nejdrive si vytvorime priznak celkovy pocet mesicu stavby a odstranime nepotrebne priznaky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V-0</th>\n      <th>V-1</th>\n      <th>V-2</th>\n      <th>V-3</th>\n      <th>V-4</th>\n      <th>V-5</th>\n      <th>V-6</th>\n      <th>V-7</th>\n      <th>V-8</th>\n      <th>V-12</th>\n      <th>...</th>\n      <th>V-23</th>\n      <th>V-24</th>\n      <th>V-25</th>\n      <th>V-26</th>\n      <th>V-27</th>\n      <th>V-28</th>\n      <th>V-29</th>\n      <th>V-9</th>\n      <th>V-10</th>\n      <th>V-30</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>85</td>\n      <td>1</td>\n      <td>3150.0</td>\n      <td>920.0</td>\n      <td>598.5</td>\n      <td>190</td>\n      <td>1010.84</td>\n      <td>16</td>\n      <td>1200</td>\n      <td>53.92</td>\n      <td>...</td>\n      <td>1755.000</td>\n      <td>8007.4</td>\n      <td>64.004</td>\n      <td>58.608</td>\n      <td>3402.236</td>\n      <td>29574.90</td>\n      <td>628132.9</td>\n      <td>2200</td>\n      <td>410</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>89</td>\n      <td>1</td>\n      <td>7600.0</td>\n      <td>1140.0</td>\n      <td>3040.0</td>\n      <td>400</td>\n      <td>963.81</td>\n      <td>23</td>\n      <td>2900</td>\n      <td>97.24</td>\n      <td>...</td>\n      <td>8647.788</td>\n      <td>8675.2</td>\n      <td>98.188</td>\n      <td>97.958</td>\n      <td>12544.810</td>\n      <td>31950.00</td>\n      <td>1188995.8</td>\n      <td>5000</td>\n      <td>1000</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>81</td>\n      <td>1</td>\n      <td>4800.0</td>\n      <td>840.0</td>\n      <td>480.0</td>\n      <td>100</td>\n      <td>689.84</td>\n      <td>15</td>\n      <td>630</td>\n      <td>38.96</td>\n      <td>...</td>\n      <td>1755.000</td>\n      <td>6161.8</td>\n      <td>42.166</td>\n      <td>34.992</td>\n      <td>1571.104</td>\n      <td>27119.60</td>\n      <td>524764.8</td>\n      <td>1200</td>\n      <td>170</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>73</td>\n      <td>1</td>\n      <td>685.0</td>\n      <td>202.0</td>\n      <td>13.7</td>\n      <td>20</td>\n      <td>459.54</td>\n      <td>4</td>\n      <td>140</td>\n      <td>11.14</td>\n      <td>...</td>\n      <td>1489.818</td>\n      <td>1528.8</td>\n      <td>10.458</td>\n      <td>9.278</td>\n      <td>522.700</td>\n      <td>18075.15</td>\n      <td>141542.6</td>\n      <td>165</td>\n      <td>30</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>90</td>\n      <td>1</td>\n      <td>3000.0</td>\n      <td>800.0</td>\n      <td>1230.0</td>\n      <td>410</td>\n      <td>631.91</td>\n      <td>13</td>\n      <td>5000</td>\n      <td>176.16</td>\n      <td>...</td>\n      <td>9272.228</td>\n      <td>9343.0</td>\n      <td>144.290</td>\n      <td>150.740</td>\n      <td>9808.600</td>\n      <td>34438.00</td>\n      <td>2318397.0</td>\n      <td>5500</td>\n      <td>700</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>367</th>\n      <td>86</td>\n      <td>20</td>\n      <td>1350.0</td>\n      <td>350.0</td>\n      <td>108.0</td>\n      <td>80</td>\n      <td>251.37</td>\n      <td>9</td>\n      <td>830</td>\n      <td>92.42</td>\n      <td>...</td>\n      <td>8548.072</td>\n      <td>8578.8</td>\n      <td>94.538</td>\n      <td>94.006</td>\n      <td>12233.302</td>\n      <td>29482.05</td>\n      <td>1067772.0</td>\n      <td>1100</td>\n      <td>150</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>368</th>\n      <td>82</td>\n      <td>20</td>\n      <td>600.0</td>\n      <td>150.0</td>\n      <td>36.0</td>\n      <td>60</td>\n      <td>299.55</td>\n      <td>6</td>\n      <td>570</td>\n      <td>55.48</td>\n      <td>...</td>\n      <td>2988.896</td>\n      <td>8005.8</td>\n      <td>66.168</td>\n      <td>60.886</td>\n      <td>3665.396</td>\n      <td>23479.00</td>\n      <td>648845.6</td>\n      <td>740</td>\n      <td>80</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>369</th>\n      <td>86</td>\n      <td>20</td>\n      <td>1900.0</td>\n      <td>430.0</td>\n      <td>285.0</td>\n      <td>150</td>\n      <td>364.41</td>\n      <td>7</td>\n      <td>640</td>\n      <td>111.38</td>\n      <td>...</td>\n      <td>8920.690</td>\n      <td>8940.2</td>\n      <td>107.640</td>\n      <td>108.684</td>\n      <td>11764.864</td>\n      <td>30216.90</td>\n      <td>1181856.2</td>\n      <td>860</td>\n      <td>220</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>370</th>\n      <td>84</td>\n      <td>20</td>\n      <td>510.0</td>\n      <td>160.0</td>\n      <td>30.6</td>\n      <td>60</td>\n      <td>245.28</td>\n      <td>9</td>\n      <td>790</td>\n      <td>69.60</td>\n      <td>...</td>\n      <td>8065.908</td>\n      <td>8118.6</td>\n      <td>79.512</td>\n      <td>76.556</td>\n      <td>6122.494</td>\n      <td>26394.75</td>\n      <td>833494.6</td>\n      <td>1100</td>\n      <td>110</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>371</th>\n      <td>81</td>\n      <td>20</td>\n      <td>890.0</td>\n      <td>230.0</td>\n      <td>35.6</td>\n      <td>40</td>\n      <td>237.03</td>\n      <td>6</td>\n      <td>350</td>\n      <td>49.08</td>\n      <td>...</td>\n      <td>1755.000</td>\n      <td>8234.6</td>\n      <td>57.476</td>\n      <td>49.152</td>\n      <td>2603.196</td>\n      <td>28750.30</td>\n      <td>601988.1</td>\n      <td>460</td>\n      <td>50</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>372 rows × 30 columns</p>\n</div>",
      "text/plain": "     V-0  V-1     V-2     V-3     V-4  V-5      V-6  V-7   V-8    V-12  ...  \\\n0     85    1  3150.0   920.0   598.5  190  1010.84   16  1200   53.92  ...   \n1     89    1  7600.0  1140.0  3040.0  400   963.81   23  2900   97.24  ...   \n2     81    1  4800.0   840.0   480.0  100   689.84   15   630   38.96  ...   \n3     73    1   685.0   202.0    13.7   20   459.54    4   140   11.14  ...   \n4     90    1  3000.0   800.0  1230.0  410   631.91   13  5000  176.16  ...   \n..   ...  ...     ...     ...     ...  ...      ...  ...   ...     ...  ...   \n367   86   20  1350.0   350.0   108.0   80   251.37    9   830   92.42  ...   \n368   82   20   600.0   150.0    36.0   60   299.55    6   570   55.48  ...   \n369   86   20  1900.0   430.0   285.0  150   364.41    7   640  111.38  ...   \n370   84   20   510.0   160.0    30.6   60   245.28    9   790   69.60  ...   \n371   81   20   890.0   230.0    35.6   40   237.03    6   350   49.08  ...   \n\n         V-23    V-24     V-25     V-26       V-27      V-28       V-29   V-9  \\\n0    1755.000  8007.4   64.004   58.608   3402.236  29574.90   628132.9  2200   \n1    8647.788  8675.2   98.188   97.958  12544.810  31950.00  1188995.8  5000   \n2    1755.000  6161.8   42.166   34.992   1571.104  27119.60   524764.8  1200   \n3    1489.818  1528.8   10.458    9.278    522.700  18075.15   141542.6   165   \n4    9272.228  9343.0  144.290  150.740   9808.600  34438.00  2318397.0  5500   \n..        ...     ...      ...      ...        ...       ...        ...   ...   \n367  8548.072  8578.8   94.538   94.006  12233.302  29482.05  1067772.0  1100   \n368  2988.896  8005.8   66.168   60.886   3665.396  23479.00   648845.6   740   \n369  8920.690  8940.2  107.640  108.684  11764.864  30216.90  1181856.2   860   \n370  8065.908  8118.6   79.512   76.556   6122.494  26394.75   833494.6  1100   \n371  1755.000  8234.6   57.476   49.152   2603.196  28750.30   601988.1   460   \n\n     V-10  V-30  \n0     410    16  \n1    1000    23  \n2     170    15  \n3      30     4  \n4     700    13  \n..    ...   ...  \n367   150     9  \n368    80     6  \n369   220     7  \n370   110     9  \n371    50     6  \n\n[372 rows x 30 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['V-30']=(data['COMPLETION YEAR']-data['START YEAR'])*4+(data['COMPLETION QUARTER']-data['START QUARTER'])  #   pocet ctvrtleti, delka doby stavby\n",
    "#   ponechame pouze rok dokonceni\n",
    "#   pocet vydanych stavebnich povoleni(V-11) mi prijde zbytecny priznak\n",
    "to_drop = ['START YEAR','COMPLETION QUARTER','START QUARTER','V-11']\n",
    "\n",
    "#   data za prubeh 5ti let zprumerujeme, ostatni vyhodime, protoze víme že tato data spolu urcite korelují, jsou na sobe závislé, potřebujeme tyto hodnoty pouze jednou\n",
    "for i in range(18):\n",
    "    x=11+i\n",
    "    row = data[['V-'+str(x),'V-'+str(x)+'.1','V-'+str(x)+'.2','V-'+str(x)+'.3','V-'+str(x)+'.4']]\n",
    "    data['V-'+str(x)] = row.mean(axis=1)\n",
    "\n",
    "for i, _ in data.iteritems():\n",
    "    if '.' in i:\n",
    "        to_drop.append(i)\n",
    "\n",
    "data = data.drop(columns=to_drop)\n",
    "data = data.rename(columns={'COMPLETION YEAR':'V-0'})\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vytvorime si funkce na rozdeleni dat, vizualizace a korelaci dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hledame teda priznaky, ktere by mohli ovlivnovat jednotlive predikce. Zkusime si to vyhodnotit podle koleracnich matic. metoda getMAE je pomocna pro rychle vypsani mean_absolute_error, pak mame jednu metodu ktera odstranuje nejmensi prispevky z X-ove mnoziny a druhou, ktera naopak odstranuje dvojice, ktere spolu koleruji natolik, ze by mohli davat zavadejici vysledky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(x_data,y_data):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=42)\n",
    "    # print('Train X shape: ', X_train.shape)\n",
    "    # print('Test X shape: ', X_test.shape)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def visualization(data,linear):   \n",
    "    plt.scatter(data, linear)\n",
    "    plt.plot([0,50], [0,50], 'r')\n",
    "    plt.show() \n",
    "\n",
    "def getMAE(type, x_tr,x_val,y_tr,y_val,opt_params={}):\n",
    "    if type == 'linear':\n",
    "        model = LinearRegression(**opt_params)\n",
    "        model.fit(x_tr,y_tr)\n",
    "        Yth = model.predict(x_val)\n",
    "        res = mean_absolute_error(Yth, np.array(y_val))\n",
    "        print('Linear regression MAE:' + str(res))\n",
    "        return res\n",
    "        \n",
    "    elif type == 'ridge':\n",
    "        model = Ridge(**opt_params)\n",
    "        model.fit(x_tr,y_tr)\n",
    "        Yth = model.predict(x_val)\n",
    "        res = mean_absolute_error(Yth, np.array(y_val))\n",
    "        print('Ridge regression MAE:' + str(res))\n",
    "        return res\n",
    "    \n",
    "    else:\n",
    "        model = RandomForestRegressor(**opt_params)\n",
    "        model.fit(x_tr,y_tr)\n",
    "        Yth = model.predict(x_val)\n",
    "        res = mean_absolute_error(Yth, np.array(y_val))\n",
    "        print('Random forest regression MAE:' + str(res))\n",
    "        return res\n",
    "\n",
    "\n",
    "def featureSelectionMaxKorelation(x_data,y_data):\n",
    "\n",
    "    #   split data\n",
    "    x_tr,x_test,y_tr,y_test = splitData(x_data,y_data)\n",
    "    x_tr,x_val,y_tr,y_val = splitData(x_tr,y_tr)\n",
    "\n",
    "    p_lr_mae = getMAE('linear',x_tr,x_val,y_tr,y_val) \n",
    "    p_rr_mae = getMAE('ridge',x_tr,x_val,y_tr,y_val)\n",
    "\n",
    "    p_x_data = x_data \n",
    "    \n",
    "    while(True):\n",
    "        print(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\")\n",
    "        #   najdi nejvice korelovane sloupce\n",
    "        corrMatrix = x_data.corr().abs()\n",
    "        corrMatrix =pd.DataFrame(corrMatrix) \n",
    "        maxs=dict()\n",
    "        for col in corrMatrix.columns:\n",
    "            v = corrMatrix[col].nlargest(2).drop(index=col)\n",
    "            index = str(np.asarray(v.index))[2:-2]\n",
    "            a = sorted([col,index])\n",
    "            maxs[a[0]+','+a[1]] = v[0]\n",
    "        to_drop = list(max(maxs,key=maxs.get).split(','))\n",
    "        _ = maxs.pop(max(maxs,key=maxs.get))\n",
    "\n",
    "        #   odstran nejmensi prispevek\n",
    "        print(\"REMOVING --> \"+ str(to_drop))\n",
    "        x_data = x_data.drop(columns=to_drop)\n",
    "\n",
    "        #   rozdel data\n",
    "        x_tr,x_test,y_tr,y_test = splitData(x_data,y_data)\n",
    "        x_tr,x_val,y_tr,y_val = splitData(x_tr,y_tr)\n",
    "\n",
    "        #   spocitej presnost\n",
    "        lr_mae = getMAE('linear',x_tr,x_val,y_tr,y_val)\n",
    "        rr_mae = getMAE('ridge',x_tr,x_val,y_tr,y_val)\n",
    "        _ = getMAE('random',x_tr,x_val,y_tr,y_val)\n",
    "\n",
    "        #   jestli je nizsi,uloz a pokracuj || jestli je vyssi, stop, vrat posledni stav\n",
    "        if(p_lr_mae >= lr_mae and p_rr_mae >= rr_mae):\n",
    "            p_lr_mae = lr_mae\n",
    "            p_rr_mae = rr_mae\n",
    "            p_x_data = x_data.copy()\n",
    "        else:\n",
    "            print(\"--------------------------\")\n",
    "            print(\"ENDING\")\n",
    "            return p_x_data\n",
    "\n",
    "\n",
    "def featureSelectionMinKorelation(x_data,y_data,column):\n",
    "\n",
    "    #   split data\n",
    "    x_data_nc = x_data.drop(columns=column)\n",
    "    x_tr,x_test,y_tr,y_test = splitData(x_data_nc,y_data)\n",
    "    x_tr,x_val,y_tr,y_val = splitData(x_tr,y_tr)\n",
    "\n",
    "    p_lr_mae = getMAE('linear',x_tr,x_val,y_tr,y_val) \n",
    "    p_rr_mae = getMAE('ridge',x_tr,x_val,y_tr,y_val)\n",
    "\n",
    "    p_x_data = x_data \n",
    "    while(True):\n",
    "        print(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\")\n",
    "        #   najdi nejvice korelovane sloupce\n",
    "        corrMatrix = x_data.corr().abs()\n",
    "        corrMatrix =pd.DataFrame(corrMatrix[column]).sort_values(by=column,ascending=True)\n",
    "        to_drop = corrMatrix.T.columns[0]\n",
    "\n",
    "        #   odstran nejmensi prispevek\n",
    "        print(\"REMOVING --> \"+ str(to_drop))\n",
    "        x_data = x_data.drop(columns=to_drop)\n",
    "        x_data_nc = x_data.drop(columns=column)\n",
    "\n",
    "        #   rozdel data\n",
    "        x_data_nc = x_data.drop(columns=column)\n",
    "        x_tr,x_test,y_tr,y_test = splitData(x_data_nc,y_data)\n",
    "        x_tr,x_val,y_tr,y_val = splitData(x_tr,y_tr)\n",
    "\n",
    "        #   spocitej presnost\n",
    "        lr_mae = getMAE('linear',x_tr,x_val,y_tr,y_val)\n",
    "        rr_mae = getMAE('ridge',x_tr,x_val,y_tr,y_val)\n",
    "        _ = getMAE('random',x_tr,x_val,y_tr,y_val)\n",
    "\n",
    "        #   jestli je nizsi,uloz a pokracuj || jestli je vyssi, stop, vrat posledni stav\n",
    "        if(p_lr_mae >= lr_mae and p_rr_mae >= rr_mae):\n",
    "            p_lr_mae = lr_mae\n",
    "            p_rr_mae = rr_mae\n",
    "            p_x_data = x_data.copy()\n",
    "        else:\n",
    "            print(\"--------------------------\")\n",
    "            print(\"ENDING\")\n",
    "            return p_x_data.drop(columns=column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mame 2 predikovane hodnoty, pro kazdou bude existovaj jiny model. Pro toty modely si najdeme nejlepsi mozne priznaky pomoci vyse vytvorenych metod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Linear regression MAE:100.42772106161414\nRidge regression MAE:99.44012327277656\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> V-30\nLinear regression MAE:100.42772106157032\nRidge regression MAE:99.42291611580784\nRandom forest regression MAE:152.9742857142857\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> V-7\nLinear regression MAE:96.99366447365969\nRidge regression MAE:96.78293308607151\nRandom forest regression MAE:153.6057142857143\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> V-3\nLinear regression MAE:90.36183529348939\nRidge regression MAE:90.24741397349881\nRandom forest regression MAE:148.53428571428577\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> V-6\nLinear regression MAE:91.85618475525504\nRidge regression MAE:91.85603230965614\nRandom forest regression MAE:145.4842857142857\n--------------------------\nENDING\nLinear regression MAE:90.36183529348939\nRidge regression MAE:90.24741397349881\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> ['V-25', 'V-26']\nLinear regression MAE:85.14037236077927\nRidge regression MAE:85.23994359161476\nRandom forest regression MAE:147.00857142857146\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> ['V-12', 'V-21']\nLinear regression MAE:87.5577865357584\nRidge regression MAE:87.59491665360552\nRandom forest regression MAE:149.77714285714285\n--------------------------\nENDING\n\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n   SALE PRICE BEST SCORE:     \nLinear regression MAE:85.14037236077927\nRidge regression MAE:85.23994359161476\nRandom forest regression MAE:144.65142857142854\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n\nLinear regression MAE:21.01043163374365\nRidge regression MAE:20.84798851594673\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> V-3\nLinear regression MAE:20.265471620498555\nRidge regression MAE:20.113323488298843\nRandom forest regression MAE:22.1\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> V-2\nLinear regression MAE:20.382866433316508\nRidge regression MAE:20.229503511333778\nRandom forest regression MAE:23.267142857142854\n--------------------------\nENDING\nLinear regression MAE:20.265471620498555\nRidge regression MAE:20.113323488298843\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> ['V-30', 'V-7']\nLinear regression MAE:23.171819875373355\nRidge regression MAE:23.112963476462696\nRandom forest regression MAE:23.127142857142857\n--------------------------\nENDING\n\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n   COST PRICE BEST SCORE:     \nLinear regression MAE:20.265471620498555\nRidge regression MAE:20.113323488298843\nRandom forest regression MAE:22.77428571428571\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n\n"
    }
   ],
   "source": [
    "#   pro predikovanou hodnotu ceny prodeje domu V-9\n",
    "SalePrice_X = featureSelectionMinKorelation(data.copy(),SalePrice_Y,'V-9')\n",
    "SalePrice_X = featureSelectionMaxKorelation(SalePrice_X,SalePrice_Y)\n",
    "\n",
    "print('\\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=')\n",
    "print(\"   SALE PRICE BEST SCORE:     \")\n",
    "n_sp_x_tr,n_sp_x_test,n_sp_y_tr,n_sp_y_test = splitData(SalePrice_X,SalePrice_Y)\n",
    "x_tr,x_val,y_tr,y_val = splitData(n_sp_x_tr,n_sp_y_tr)\n",
    "lr_mae = getMAE('linear',x_tr,x_val,y_tr,y_val)\n",
    "rr_mae = getMAE('ridge',x_tr,x_val,y_tr,y_val)\n",
    "_ = getMAE('random',x_tr,x_val,y_tr,y_val)\n",
    "print('-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\\n')\n",
    "\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "#    SALE PRICE BEST SCORE:     \n",
    "# Linear regression MAE:85.14037236077927\n",
    "# Ridge regression MAE:85.23994359161476\n",
    "# Random forest regression MAE:135.55714285714282\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "#   pro predikovanou hodnotu ceny stavby donu V-9\n",
    "CostPrice_X = featureSelectionMinKorelation(data.copy(),CostPrice_Y,'V-10')\n",
    "CostPrice_X = featureSelectionMaxKorelation(CostPrice_X,CostPrice_Y)\n",
    "\n",
    "print('\\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=')\n",
    "print(\"   COST PRICE BEST SCORE:     \")\n",
    "n_cp_x_tr,n_cp_x_test,n_cp_y_tr,n_cp_y_test = splitData(CostPrice_X,CostPrice_Y)\n",
    "x_tr,x_val,y_tr,y_val = splitData(n_cp_x_tr,n_cp_y_tr)\n",
    "lr_mae = getMAE('linear',x_tr,x_val,y_tr,y_val)\n",
    "rr_mae = getMAE('ridge',x_tr,x_val,y_tr,y_val)\n",
    "_ = getMAE('random',x_tr,x_val,y_tr,y_val)\n",
    "print('-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\\n')\n",
    "\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "#    COST PRICE BEST SCORE:     \n",
    "# Linear regression MAE:20.265471620498555\n",
    "# Ridge regression MAE:20.113323488298843\n",
    "# Random forest regression MAE:22.14571428571429\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ted zkusíme data standardizovat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "s_data = pd.DataFrame(scaler.transform(data),columns=(data.columns))\n",
    "# display(s_data)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A podivat se, jestli se nam presnost modelu zlepsila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Linear regression MAE:100.4277210616299\nRidge regression MAE:91.32162940110996\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> V-30\nLinear regression MAE:100.42772106163017\nRidge regression MAE:91.33036325724674\nRandom forest regression MAE:151.38142857142856\n--------------------------\nENDING\nLinear regression MAE:100.4277210616299\nRidge regression MAE:91.32162940110996\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> ['V-30', 'V-7']\nLinear regression MAE:96.99366447366619\nRidge regression MAE:95.52629235278889\nRandom forest regression MAE:151.11142857142855\n--------------------------\nENDING\n\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n   SALE PRICE BEST SCORE:     \nLinear regression MAE:100.4277210616299\nRidge regression MAE:91.32162940110996\nRandom forest regression MAE:145.27571428571432\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n\nLinear regression MAE:21.01043163372758\nRidge regression MAE:19.358119562141688\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> V-3\nLinear regression MAE:20.26547162050385\nRidge regression MAE:19.061240126921355\nRandom forest regression MAE:22.475714285714282\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> V-2\nLinear regression MAE:20.382866433324278\nRidge regression MAE:19.209829929121707\nRandom forest regression MAE:22.04714285714286\n--------------------------\nENDING\nLinear regression MAE:20.26547162050385\nRidge regression MAE:19.061240126921355\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\nREMOVING --> ['V-30', 'V-7']\nLinear regression MAE:23.171819875383054\nRidge regression MAE:20.74066349944503\nRandom forest regression MAE:23.817142857142855\n--------------------------\nENDING\n\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n   COST PRICE BEST SCORE:     \nLinear regression MAE:20.26547162050385\nRidge regression MAE:19.061240126921355\nRandom forest regression MAE:23.282857142857143\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n\n"
    }
   ],
   "source": [
    "#   pro predikovanou hodnotu ceny prodeje domu V-9\n",
    "s_SalePrice_X = featureSelectionMinKorelation(s_data.copy(),SalePrice_Y,'V-9')\n",
    "s_SalePrice_X = featureSelectionMaxKorelation(s_SalePrice_X,SalePrice_Y)\n",
    "\n",
    "print('\\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=')\n",
    "print(\"   SALE PRICE BEST SCORE:     \")\n",
    "s_sp_x_tr,s_sp_x_test,s_sp_y_tr,s_sp_y_test = splitData(s_SalePrice_X,SalePrice_Y)\n",
    "x_tr,x_val,y_tr,y_val = splitData(s_sp_x_tr,s_sp_y_tr)\n",
    "lr_mae = getMAE('linear',x_tr,x_val,y_tr,y_val)\n",
    "rr_mae = getMAE('ridge',x_tr,x_val,y_tr,y_val)\n",
    "_ = getMAE('random',x_tr,x_val,y_tr,y_val)\n",
    "print('-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\\n')\n",
    "\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "#    SALE PRICE BEST SCORE:     \n",
    "# Linear regression MAE:100.4277210616299\n",
    "# Ridge regression MAE:91.32162940110996\n",
    "# Random forest regression MAE:135.65428571428572\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "#   pro predikovanou hodnotu ceny stavby donu V-9\n",
    "s_CostPrice_X = featureSelectionMinKorelation(s_data.copy(),CostPrice_Y,'V-10')\n",
    "s_CostPrice_X = featureSelectionMaxKorelation(s_CostPrice_X,CostPrice_Y)\n",
    "\n",
    "print('\\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=')\n",
    "print(\"   COST PRICE BEST SCORE:     \")\n",
    "s_cp_x_tr,s_cp_x_test,s_cp_y_tr,s_cp_y_test = splitData(s_CostPrice_X,CostPrice_Y)\n",
    "x_tr,x_val,y_tr,y_val = splitData(s_cp_x_tr,s_cp_y_tr)\n",
    "lr_mae = getMAE('linear',x_tr,x_val,y_tr,y_val)\n",
    "rr_mae = getMAE('ridge',x_tr,x_val,y_tr,y_val)\n",
    "_ = getMAE('random',x_tr,x_val,y_tr,y_val)\n",
    "print('-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\\n')\n",
    "\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "#    COST PRICE BEST SCORE:     \n",
    "# Linear regression MAE:20.26547162050385\n",
    "# Ridge regression MAE:19.061240126921355\n",
    "# Random forest regression MAE:22.955714285714286\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Porovnani:\n",
    "   pred standardizaci                                              po standardizaci\n",
    "   \n",
    "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=                     -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "   COST PRICE BEST SCORE:                                       COST PRICE BEST SCORE:     \n",
    "Linear regression MAE:20.265471620498555                     Linear regression MAE:20.26547162050385\n",
    "Ridge regression MAE:20.113323488298843                      Ridge regression MAE:19.061240126921355\n",
    "Random forest regression MAE:22.14571428571429               Random forest regression MAE:22.955714285714286      \n",
    "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=                     -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=                     -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "   SALE PRICE BEST SCORE:                                       SALE PRICE BEST SCORE:        \n",
    "Linear regression MAE:85.14037236077927                      Linear regression MAE:100.4277210616299\n",
    "Ridge regression MAE:85.23994359161476                       Ridge regression MAE:91.32162940110996\n",
    "Random forest regression MAE:135.55714285714282              Random forest regression MAE:135.65428571428572\n",
    "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=                     -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní zkusme iterovat přes množinu různých parametrů a vypsat si jejich skóre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "optimal parameters for linear regression costPrice: {'fit_intercept': True, 'n_jobs': None, 'normalize': False}\noptimal parameters for linear regression salePrice: {'fit_intercept': True, 'n_jobs': None, 'normalize': False}\noptimal parameters for ridge regression costPrice: {'fit_intercept': True, 'max_iter': None, 'normalize': False, 'solver': 'svd'}\noptimal parameters for ridge regression salePrice: {'fit_intercept': True, 'max_iter': None, 'normalize': False, 'solver': 'svd'}\noptimal parameters for random forest costPrice: {'max_depth': 7, 'max_features': 'auto', 'n_estimators': 6}\noptimal parameters for random forest salePrice: {'max_depth': 7, 'max_features': 'auto', 'n_estimators': 26}\n"
    }
   ],
   "source": [
    "#   linear regresion hyperparametry --> moc jich tam k ladeni neni\n",
    "param_grid = {\n",
    "    \"fit_intercept\" : [True, False],\n",
    "    \"normalize\" : [True, False],    #   bezi pokud je fit_intercept == false\n",
    "    \"n_jobs\" : [None,1,10,20]\n",
    "}\n",
    "\n",
    "cp_lr_gs = GridSearchCV(estimator = LinearRegression(), param_grid = param_grid, cv = 3, verbose=0)\n",
    "cp_lr_gs.fit(n_cp_x_tr,n_cp_y_tr)\n",
    "print(\"optimal parameters for linear regression costPrice: \"+ str(cp_lr_gs.best_params_))\n",
    "\n",
    "\n",
    "sp_lr_gs = GridSearchCV(estimator = LinearRegression(), param_grid = param_grid, cv = 3, verbose=0)\n",
    "sp_lr_gs.fit(n_sp_x_tr,n_sp_y_tr)\n",
    "print(\"optimal parameters for linear regression salePrice: \"+ str(sp_lr_gs.best_params_))\n",
    "\n",
    "\n",
    "#   ridge regression hyperparametry\n",
    "param_grid = {\n",
    "    \"fit_intercept\" : [True, False],\n",
    "    \"normalize\" : [True, False],    #   bezi pokud je fit_intercept == false\n",
    "    \"max_iter\" : [None,1,10,20],\n",
    "    \"solver\": [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]\n",
    "}\n",
    "\n",
    "cp_rr_gs = GridSearchCV(estimator = Ridge(), param_grid = param_grid, cv = 3, verbose=0)\n",
    "cp_rr_gs.fit(n_cp_x_tr,n_cp_y_tr)\n",
    "print(\"optimal parameters for ridge regression costPrice: \"+ str(cp_rr_gs.best_params_))\n",
    "\n",
    "\n",
    "sp_rr_gs = GridSearchCV(estimator = Ridge(), param_grid = param_grid, cv = 3, verbose=0)\n",
    "sp_rr_gs.fit(n_sp_x_tr,n_sp_y_tr)\n",
    "print(\"optimal parameters for ridge regression salePrice: \"+ str(sp_rr_gs.best_params_))\n",
    "\n",
    "#   random forest hyperparametry\n",
    "param_grid = {\n",
    "    \"n_estimators\" : range(1,100,5),\n",
    "    \"max_features\" : ['auto', 'sqrt'],\n",
    "    \"max_depth\" : range(1,10)\n",
    "}\n",
    "\n",
    "cp_fr_gs = GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_grid, cv = 3, verbose=0)\n",
    "cp_fr_gs.fit(n_cp_x_tr,n_cp_y_tr)\n",
    "print(\"optimal parameters for random forest costPrice: \"+ str(cp_fr_gs.best_params_))\n",
    "\n",
    "\n",
    "sp_fr_gs = GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_grid, cv = 3, verbose=0)\n",
    "sp_fr_gs.fit(n_sp_x_tr,n_sp_y_tr)\n",
    "print(\"optimal parameters for random forest salePrice: \"+ str(sp_fr_gs.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na závěr vypíšeme všechny MAE pro nestandardizovana (vyslo to lepe) data pro vsechny modely na testovaci mnozine, ktera je zatim nedotcena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n   COST PRICE BEST SCORE:     \nLinear regression MAE:18.492311209794\nRidge regression MAE:18.48144411734697\nRandom forest regression MAE:21.78052645923296\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n\n\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n   SALE PRICE BEST SCORE:     \nLinear regression MAE:131.8593288342705\nRidge regression MAE:131.84115246612586\nRandom forest regression MAE:176.44086021505376\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n\n"
    }
   ],
   "source": [
    "print('\\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=')\n",
    "print(\"   COST PRICE BEST SCORE:     \")\n",
    "lr_mae = getMAE('linear',n_cp_x_tr,n_cp_x_test,n_cp_y_tr,n_cp_y_test, cp_lr_gs.best_params_)\n",
    "rr_mae = getMAE('ridge',n_cp_x_tr,n_cp_x_test,n_cp_y_tr,n_cp_y_test, cp_rr_gs.best_params_)\n",
    "_ = getMAE('random',n_cp_x_tr,n_cp_x_test,n_cp_y_tr,n_cp_y_test, cp_fr_gs.best_params_)\n",
    "print('-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\\n')\n",
    "\n",
    "print('\\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=')\n",
    "print(\"   SALE PRICE BEST SCORE:     \")\n",
    "lr_mae = getMAE('linear',n_sp_x_tr,n_sp_x_test,n_sp_y_tr,n_sp_y_test)\n",
    "rr_mae = getMAE('ridge',n_sp_x_tr,n_sp_x_test,n_sp_y_tr,n_sp_y_test)\n",
    "_ = getMAE('random',n_sp_x_tr,n_sp_x_test,n_sp_y_tr,n_sp_y_test)\n",
    "print('-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absolutni chyba na testovacich datech je pro predikci SalePrice docela vyrazne vyssi nez na datech testovacich. Naopak u predikce CostPrice vidime i vyssi presnost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}