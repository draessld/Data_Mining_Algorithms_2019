{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 2 - předzpracování dat a binární klasifikace (do 10. listopadu)\n",
    "\n",
    "  * Cílem thoto úkolu je vyzkoušet si naučit prediktivní model pro binární klasifikaci.\n",
    "  * Budete se muset vypořádat s příznaky, které jsou různých typů a které bude třeba nějakým způsobem převést do číselné reprezentace.\n",
    "    \n",
    "> **Úkoly jsou zadány tak, aby Vám daly prostor pro invenci. Vymyslet _jak přesně_ budete úkol řešit, je důležitou součástí zadání a originalita či nápaditost bude také hodnocena!**\n",
    "\n",
    "## Zdroj dat\n",
    "\n",
    "Budeme se zabývat predikcí přežití pasažérů Titaniku.\n",
    "K dispozici máte trénovací data v souboru **data.csv** a data na vyhodnocení v souboru **evaluation.csv**.\n",
    "\n",
    "#### Seznam příznaků:\n",
    "* survived - zda přežil, 0 = Ne, 1 = Ano, **vysvětlovaná proměnná**, kterou chcete predikovat\n",
    "* pclass - Třída lodního lístku, 1 = první, 2 = druhá, 3 = třetí\n",
    "* name - jméno\n",
    "* sex - pohlaví\n",
    "* age - věk v letech\n",
    "* sibsp\t- počet sourozenců / manželů, manželek na palubě\n",
    "* parch - počet rodičů / dětí na palubě\n",
    "* ticket - číslo lodního lístku\n",
    "* fare - cena lodního lístku\n",
    "* cabin\t- číslo kajuty\n",
    "* embarked\t- místo nalodění, C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "* home.dest - Bydliště/Cíl\n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "**Základní body zadání**, za jejichž (poctivé) vypracování získáte **8 bodů**:\n",
    "  * V Jupyter notebooku načtěte data ze souboru **data.csv**. Vhodným způsobem si je rozdělte na trénovací, testovací a případně i validační množinu (preferujeme ale použití cross-validation).\n",
    "  * Projděte si jednotlivé příznaky a transformujte je do vhodné podoby pro použití ve vybraném klasifikačním modelu.\n",
    "  * Podle potřeby si můžete vytvářet nové příznaky (na základě existujících), například tedy můžete vytvořit příznak měřící délku jména. Některé příznaky můžete také úplně zahodit.\n",
    "  * Nějakým způsobem se vypořádejte s chybějícími hodnotami.\n",
    "  * Následně si vyberte vhodný klasifikační model z přednášek. Najděte vhodné hyperparametry a určete jeho přesnost (accuracy) na trénovací množině. Také určete jeho přesnost na testovací/vaidační množině.\n",
    "  * Načtěte vyhodnocovací data ze souboru **evaluation.csv**. Napočítejte predikce pro tyto data (vysvětlovaná proměnná v nich již není). Vytvořte **results.csv** soubor, ve kterém tyto predikce uložíte do dvou sloupců: ID, predikce přežití. Tento soubor nahrajte do repozitáře.\n",
    "\n",
    "**Další body zadání** za případné další body  (můžete si vybrat, maximum bodů za úkol je každopádně 12 bodů):\n",
    "  * (až +4 body) Aplikujte všechny klasifikační modely z přednášek a určete (na základě přesnosti na validační množině), který je nejlepší. Přesnost tohoto nejlepšího modelu odhadněte pomocí testovací množiny. K predikcím na vyhodnocovacích datech využijte tento model.\n",
    "  * (až +4 body) Zkuste použít nějaké (alespoň dvě) netriviální metody doplňování chybějících hodnot u věku. Zaměřte na vliv těchto metod na přesnost predikce výsledného modelu. K predikcím na vyhodnocovacích datech využijte ten přístup, který Vám vyjde jako nejlepší.\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-VZD/homeworks/index.html.\n",
    "  * Odevzdejte nejen Jupyter Notebook, ale i _csv_ soubor(y) s predikcemi pro vyhodnocovací data.\n",
    "  * Opravující Vám může umožnit úkol dodělat či opravit a získat tak další body. **První verze je ale důležitá a bude-li odbytá, budete za to penalizováni**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### odtud už je to Vaše\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkce\n",
    "\n",
    "def edit_oddil(val):\n",
    "    if type(val) != float:\n",
    "        return val[:1]\n",
    "    else: \n",
    "        return np.nan\n",
    "    \n",
    "def encode_categories(df, mappers, dummies=False):\n",
    "    le = LabelEncoder()\n",
    "    for col in df.select_dtypes('object').columns:\n",
    "        if col not in mappers and df[col].nunique() < 30:\n",
    "            df[col] = df[col].fillna('NaN')\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            if dummies:\n",
    "                prefix = 'd_' + col\n",
    "                df = pd.concat([df.drop(columns=[col]), pd.get_dummies(df[col], prefix=prefix)], axis=1)\n",
    "        elif col in mappers:\n",
    "            df[col] = df[col].replace(mappers[col])\n",
    "        elif df[col].nunique() > 30:\n",
    "            df = df.drop(columns=[col])\n",
    "    return df    \n",
    "\n",
    "def replace_nans(df, cols_nan):\n",
    "    for col in cols_nan:\n",
    "        d1 = df[df[col].isnull()]\n",
    "        d2 = df[df[col].notnull()]\n",
    "        \n",
    "        y = d2[col]\n",
    "        x = d2.drop(columns=cols_nan)\n",
    "        x2 = d1.drop(columns=cols_nan)\n",
    "\n",
    "        if df[col].dtype == 'float64':\n",
    "            model = KNeighborsRegressor(n_neighbors=5)\n",
    "        else:\n",
    "            model = KNeighborsClassifier(n_neighbors=5)\n",
    "        \n",
    "        model.fit(x,y)\n",
    "        y2 = model.predict(x2)\n",
    "        \n",
    "        df[col][df[col].isnull()] = y2  \n",
    "    return df\n",
    "\n",
    "def cross_val(x, y, folds, model, dummies = False):\n",
    "    score = 0\n",
    "    np.random.seed(seed=654) \n",
    "    \n",
    "    if not dummies:\n",
    "            x = x.loc[:, x.nunique() > 2]   \n",
    "            \n",
    "    fold_idx = np.random.randint(folds, size=x.shape[0])\n",
    "    \n",
    "    for fold in range(folds):\n",
    "        xtr = x[ fold_idx != fold ]\n",
    "        xval   = x[ fold_idx == fold ]\n",
    "        ytr = y[ fold_idx != fold ]\n",
    "        yval   = y[ fold_idx == fold ]        \n",
    "\n",
    "        model.fit(xtr, ytr)\n",
    "        score += metrics.accuracy_score(ytr, model.predict(xtr))\n",
    "        \n",
    "    return score/folds\n",
    "\n",
    "def normalization(xtrain,xtest):\n",
    "    one_val_cols = xtrain.loc[:,xtrain.max(axis=0) - xtrain.min(axis=0) == 0].columns \n",
    "    xtrain.drop(columns=one_val_cols, inplace=True)\n",
    "    xtest.drop(columns=one_val_cols, inplace=True)\n",
    "    \n",
    "    xtrain = (xtrain - xtrain.min(axis=0)) / (xtrain.max(axis=0) - xtrain.min(axis=0))\n",
    "    xtest = (xtest - xtrain.min(axis=0)) / (xtest.max(axis=0) - xtrain.min(axis=0))\n",
    "    \n",
    "    return xtrain,xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/domka/.local/share/virtualenvs/VZD-tFrAp-mM/lib/python3.6/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/domka/.local/share/virtualenvs/VZD-tFrAp-mM/lib/python3.6/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>oddil</th>\n",
       "      <th>d_sex_0</th>\n",
       "      <th>d_sex_1</th>\n",
       "      <th>d_embarked_0</th>\n",
       "      <th>d_embarked_1</th>\n",
       "      <th>...</th>\n",
       "      <th>d_osloveni_7</th>\n",
       "      <th>d_osloveni_8</th>\n",
       "      <th>d_osloveni_9</th>\n",
       "      <th>d_osloveni_10</th>\n",
       "      <th>d_osloveni_11</th>\n",
       "      <th>d_osloveni_12</th>\n",
       "      <th>d_osloveni_13</th>\n",
       "      <th>d_osloveni_14</th>\n",
       "      <th>d_osloveni_15</th>\n",
       "      <th>d_osloveni_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass  age  sibsp  parch  oddil  d_sex_0  d_sex_1  \\\n",
       "0           1       3   22      0      0      5        1        0   \n",
       "1           0       3   31      0      0      4        0        1   \n",
       "2           1       1   19      1      0      1        1        0   \n",
       "3           0       3   25      0      0      4        0        1   \n",
       "4           0       3   31      0      0      4        0        1   \n",
       "..        ...     ...  ...    ...    ...    ...      ...      ...   \n",
       "995         1       1   48      1      1      1        1        0   \n",
       "996         1       2    3      1      2      1        1        0   \n",
       "997         1       3   19      0      0      4        1        0   \n",
       "998         1       3   32      0      0      4        0        1   \n",
       "999         0       1   56      0      0      2        0        1   \n",
       "\n",
       "     d_embarked_0  d_embarked_1  ...  d_osloveni_7  d_osloveni_8  \\\n",
       "0               0             0  ...             0             0   \n",
       "1               0             0  ...             0             0   \n",
       "2               1             0  ...             0             0   \n",
       "3               1             0  ...             0             0   \n",
       "4               0             0  ...             0             0   \n",
       "..            ...           ...  ...           ...           ...   \n",
       "995             1             0  ...             0             0   \n",
       "996             1             0  ...             0             0   \n",
       "997             0             0  ...             0             0   \n",
       "998             0             0  ...             0             0   \n",
       "999             0             0  ...             0             0   \n",
       "\n",
       "     d_osloveni_9  d_osloveni_10  d_osloveni_11  d_osloveni_12  d_osloveni_13  \\\n",
       "0               1              0              0              0              0   \n",
       "1               0              0              0              1              0   \n",
       "2               0              0              0              0              1   \n",
       "3               0              0              0              1              0   \n",
       "4               0              0              0              1              0   \n",
       "..            ...            ...            ...            ...            ...   \n",
       "995             0              0              0              0              1   \n",
       "996             1              0              0              0              0   \n",
       "997             1              0              0              0              0   \n",
       "998             0              0              0              1              0   \n",
       "999             0              0              0              1              0   \n",
       "\n",
       "     d_osloveni_14  d_osloveni_15  d_osloveni_16  \n",
       "0                0              0              0  \n",
       "1                0              0              0  \n",
       "2                0              0              0  \n",
       "3                0              0              0  \n",
       "4                0              0              0  \n",
       "..             ...            ...            ...  \n",
       "995              0              0              0  \n",
       "996              0              0              0  \n",
       "997              0              0              0  \n",
       "998              0              0              0  \n",
       "999              0              0              0  \n",
       "\n",
       "[1000 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# načíst a upravit data \n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "# rozlisit nominalni a ordinalni neciselne priznaky a prevest je na ciselne\n",
    "data['oddil'] = data['cabin'].apply(edit_oddil)\n",
    "\n",
    "n = data['home.dest'].str.rsplit(',',1,expand=True)\n",
    "data['home.dest'] = n[1]\n",
    "\n",
    "n = data['name'].str.rsplit(',',1,expand=True)[1].str.split('.',1,expand=True)\n",
    "data['osloveni'] = n[0]\n",
    "\n",
    "to_drop = ['cabin','name','ticket','ID','fare']\n",
    "data = data.drop(columns=to_drop,axis=1)\n",
    "# display(data['oddil'].unique())\n",
    "\n",
    "mappers = {}\n",
    "mappers['oddil'] = {ch: n for n, ch in enumerate(string.ascii_uppercase)}\n",
    "\n",
    "# label encoding zpusob predzpracovani\n",
    "data = encode_categories(data,mappers,True)\n",
    "\n",
    "# odstraneni Nan hodnot pomoci knn predikce\n",
    "cols_nan = data.loc[:,data.isnull().sum() > 0].columns\n",
    "data = replace_nans(data,cols_nan)\n",
    "data[['age','oddil']] = data[['age','oddil']].astype(int)\n",
    "\n",
    "display(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rozdel data na testovaci a trenovaci sadu\n",
    "\n",
    "ydata = data['survived']\n",
    "xdata = data.loc[:, data.columns != 'survived']\n",
    "\n",
    "rd_seed = 333\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(xdata, ydata, test_size=0.25, random_state=rd_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 18}\n",
      "accuracy on train data: 0.9506666666666667\n",
      "accuracy on test data: 0.796\n"
     ]
    }
   ],
   "source": [
    "# jednoduchy model stromu\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": range(5,100)\n",
    "}\n",
    "\n",
    "# cross validation\n",
    "param_comb = ParameterGrid(param_grid)\n",
    "val_acc = 0\n",
    "for params in param_comb:\n",
    "    dt = DecisionTreeClassifier(**params)\n",
    "    score = cross_val(xtrain.copy(), ytrain, 10, dt, True)\n",
    "    if val_acc < score:\n",
    "        opt_params_dt = params\n",
    "        val_acc = score\n",
    "print(opt_params_dt)\n",
    "\n",
    "dt = DecisionTreeClassifier(**opt_params_dt)\n",
    "dt.fit(xtrain,ytrain)\n",
    "print('accuracy on train data: ' +str(metrics.accuracy_score(ytrain, dt.predict(xtrain))))\n",
    "print('accuracy on test data: ' +str(metrics.accuracy_score(ytest, dt.predict(xtest))))\n",
    "\n",
    "acc_dt = metrics.accuracy_score(ytest, dt.predict(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'n_estimators': 76}\n",
      "accuracy on train data: 0.9013333333333333\n",
      "accuracy on test data: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Bagging: nahodne lesy\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": range(1,100,5),\n",
    "    \"max_depth\": range(1,10)\n",
    "}\n",
    "\n",
    "# cross validation\n",
    "param_comb = ParameterGrid(param_grid)\n",
    "val_acc = 0\n",
    "for params in param_comb:\n",
    "    rfc = RandomForestClassifier(**params,random_state=0)\n",
    "    score = cross_val(xtrain.copy(), ytrain, 10, rfc, True)\n",
    "    if val_acc < score:\n",
    "        opt_params_rfc = params\n",
    "        val_acc = score\n",
    "print(opt_params_rfc)\n",
    "\n",
    "# create forest\n",
    "rfc = RandomForestClassifier(**opt_params_rfc)\n",
    "rfc.fit(xtrain, ytrain)\n",
    "print('accuracy on train data: ' +str(metrics.accuracy_score(ytrain, rfc.predict(xtrain))))\n",
    "print('accuracy on test data: ' +str(metrics.accuracy_score(ytest, rfc.predict(xtest))))\n",
    "\n",
    "acc_rfc = metrics.accuracy_score(ytest, rfc.predict(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1, 'n_estimators': 96}\n",
      "accuracy on train data: 0.8306666666666667\n",
      "accuracy on test data: 0.804\n"
     ]
    }
   ],
   "source": [
    "# Boosting: AdaBoost\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': range(1,100,5),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5, 1]\n",
    "}\n",
    "\n",
    "# cross validation\n",
    "param_comb = ParameterGrid(param_grid)\n",
    "val_acc = 0\n",
    "for params in param_comb:\n",
    "    ada = AdaBoostClassifier(**params)\n",
    "    score = cross_val(xtrain.copy(), ytrain, 10, ada, True)\n",
    "    if val_acc < score:\n",
    "        opt_params_ada = params\n",
    "        val_acc = score\n",
    "print(opt_params_ada)\n",
    "\n",
    "# create ada\n",
    "ada = AdaBoostClassifier(**opt_params_ada)\n",
    "ada.fit(xtrain, ytrain)\n",
    "print('accuracy on train data: ' +str(metrics.accuracy_score(ytrain, ada.predict(xtrain))))\n",
    "print('accuracy on test data: ' +str(metrics.accuracy_score(ytest, ada.predict(xtest))))\n",
    "\n",
    "acc_ada = metrics.accuracy_score(ytest, ada.predict(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "accuracy on train data: 0.952\n",
      "accuracy on test data: 0.816\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors' : range(1,20),\n",
    "    'p': range(1,5),\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "#cross validation\n",
    "param_comb = ParameterGrid(param_grid)\n",
    "\n",
    "val_acc = 0\n",
    "for params in param_comb:\n",
    "    knn = KNeighborsClassifier(**params)\n",
    "    score = cross_val(xtrain.copy(), ytrain, 12, knn, True)\n",
    "    if val_acc < score:\n",
    "        opt_params_knn = params\n",
    "        val_acc = score\n",
    "print(opt_params_knn)\n",
    "\n",
    "\n",
    "# create KNN\n",
    "knn = KNeighborsClassifier(**opt_params_knn)\n",
    "knn.fit(xtrain,ytrain)\n",
    "print('accuracy on train data: ' +str(metrics.accuracy_score(ytrain, knn.predict(xtrain))))\n",
    "print('accuracy on test data: ' +str(metrics.accuracy_score(ytest, knn.predict(xtest))))\n",
    "\n",
    "acc_knn = metrics.accuracy_score(ytest, knn.predict(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train data: 0.8213333333333334\n",
      "accuracy on test data: 0.824\n"
     ]
    }
   ],
   "source": [
    "# logisticka regrese\n",
    "\n",
    "lgr = LogisticRegression(solver='newton-cg')\n",
    "lgr.fit(xtrain,ytrain)\n",
    "\n",
    "print('accuracy on train data: ' +str(metrics.accuracy_score(ytrain, lgr.predict(xtrain))))\n",
    "print('accuracy on test data: ' +str(metrics.accuracy_score(ytest, lgr.predict(xtest))))\n",
    "      \n",
    "acc_lgr = metrics.accuracy_score(ytest, lgr.predict(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796\n",
      "0.82\n",
      "0.804\n",
      "0.816\n",
      "0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/domka/.local/share/virtualenvs/VZD-tFrAp-mM/lib/python3.6/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/domka/.local/share/virtualenvs/VZD-tFrAp-mM/lib/python3.6/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-3c6ed98045b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSurvived\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/VZD-tFrAp-mM/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ID'"
     ]
    }
   ],
   "source": [
    "# evaluation data to test model\n",
    "\n",
    "test_data = pd.read_csv('evaluation.csv')\n",
    "\n",
    "# uprav data stejnym zpusobem jako predchozi\n",
    "test_data['oddil'] = test_data['cabin'].apply(edit_oddil)\n",
    "\n",
    "n = test_data['home.dest'].str.rsplit(',',1,expand=True)[1]\n",
    "test_data['home.dest'] = n[1]\n",
    "\n",
    "n = test_data['name'].str.rsplit(',',1,expand=True)[1].str.split('.',1,expand=True)\n",
    "test_data['osloveni'] = n[0]\n",
    "\n",
    "to_drop = ['cabin','name','ticket','ID','fare','home.dest']\n",
    "test_data = test_data.drop(columns=to_drop)\n",
    "\n",
    "test_data = encode_categories(test_data.copy(),mappers,True)\n",
    "\n",
    "cols_nan = test_data.loc[:,test_data.isnull().sum() > 0].columns\n",
    "test_data = replace_nans(test_data.copy(),cols_nan)\n",
    "test_data[['age','oddil']] = test_data[['age','oddil']].astype(int)\n",
    "\n",
    "to_add = [item for item in data.columns.drop('survived') if item not in test_data.columns]\n",
    "test_data[to_add] = pd.DataFrame(0, index=range(data.shape[0]), columns=to_add)\n",
    "\n",
    "# vyber nejlepsi model\n",
    "print(acc_dt)\n",
    "print(acc_rfc)\n",
    "print(acc_ada)\n",
    "print(acc_knn)\n",
    "print(acc_lgr)\n",
    "# decission tree ma nejlepsi presnost\n",
    "\n",
    "ypred = lgr.predict(test_data)\n",
    "result = pd.DataFrame(columns=['ID','Survived'])\n",
    "result.ID = test_data.ID\n",
    "result.Survived = ypred\n",
    "result.to_csv('results.csv',index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
